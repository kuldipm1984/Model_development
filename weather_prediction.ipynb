{"cells":[{"cell_type":"code","execution_count":null,"id":"8fd9813b-33c6-4144-85d0-ed375bd44010","metadata":{"id":"8fd9813b-33c6-4144-85d0-ed375bd44010","outputId":"52a5e823-0f5c-4861-8892-e39f704b505f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow_addons in d:\\anaconda\\lib\\site-packages (0.22.0)\n","Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (1.26.4)\n","Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (2.1.4)\n","Requirement already satisfied: typeguard<3.0.0,>=2.7 in d:\\anaconda\\lib\\site-packages (from tensorflow_addons) (2.13.3)\n","Requirement already satisfied: packaging in d:\\anaconda\\lib\\site-packages (from tensorflow_addons) (23.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\lib\\site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in d:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n","Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"]}],"source":["!pip install tensorflow_addons numpy pandas"]},{"cell_type":"code","execution_count":null,"id":"7dd1ddfe-3020-4af6-b084-43d85c941c10","metadata":{"id":"7dd1ddfe-3020-4af6-b084-43d85c941c10"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import Input, Dense, LSTM,LayerNormalization, MultiHeadAttention, Dropout\n","from tensorflow.keras.models import Model\n","from sklearn.preprocessing import MinMaxScaler"]},{"cell_type":"code","execution_count":null,"id":"02e9380d-e3f9-43ae-a5a2-a77054432644","metadata":{"id":"02e9380d-e3f9-43ae-a5a2-a77054432644"},"outputs":[],"source":["# Load dataset\n","df = pd.read_csv('weatherstats_toronto_daily.csv')\n","df.fillna(0, inplace=True)\n","df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y')\n","df['EWMA_max_temperature'] = df['max_temperature'].ewm(span=7).mean()\n","df['EWMA_min_temperature'] = df['min_temperature'].ewm(span=7).mean()\n","df.set_index('date', inplace=True)"]},{"cell_type":"code","execution_count":null,"id":"aab2b757-1526-4946-8acb-0deee3818929","metadata":{"id":"aab2b757-1526-4946-8acb-0deee3818929"},"outputs":[],"source":["def add_seasonal_features(df, timestamp_col, period, fourier_order):\n","    time = df.index.dayofyear\n","    for k in range(1, fourier_order + 1):\n","        df[f'sin_{period}_{k}'] = np.sin(2 * np.pi * k * time / period)\n","        df[f'cos_{period}_{k}'] = np.cos(2 * np.pi * k * time / period)\n","    return df\n","\n","# Add yearly seasonal features (365 days in a year)\n","df = add_seasonal_features(df, timestamp_col='date', period=365, fourier_order=4)"]},{"cell_type":"code","execution_count":null,"id":"34e522f1-ad8f-4e2a-aa84-c79290565ecc","metadata":{"id":"34e522f1-ad8f-4e2a-aa84-c79290565ecc","outputId":"63da29bf-1fac-4427-dec5-dd07c71112a6"},"outputs":[{"data":{"text/plain":["array([[0.45670628, 0.47903977, 0.48014122, ..., 0.29334761, 0.23099492,\n","        0.92146931],\n","       [0.36162988, 0.37620924, 0.37069726, ..., 0.27012011, 0.2026339 ,\n","        0.90196217],\n","       [0.47028862, 0.46202078, 0.44660194, ..., 0.24750554, 0.17568222,\n","        0.88054992],\n","       ...,\n","       [0.38539898, 0.42135435, 0.43159753, ..., 0.99401122, 0.6025532 ,\n","        0.98936984],\n","       [0.38539898, 0.43837334, 0.44112974, ..., 0.99733536, 0.56864002,\n","        0.99526614],\n","       [0.36672326, 0.39161591, 0.38217123, ..., 0.9993334 , 0.53440153,\n","        0.99881513]])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Normalize the Data\n","scaler = MinMaxScaler()\n","df_numeric = df.select_dtypes(include=[np.number])\n","data_scaled = scaler.fit_transform(df_numeric)\n","data_scaled"]},{"cell_type":"code","execution_count":null,"id":"08fba322-9c9f-4f52-8a3a-9823f34cfbe9","metadata":{"id":"08fba322-9c9f-4f52-8a3a-9823f34cfbe9"},"outputs":[],"source":["# Define Window Size\n","time_steps = 30\n","forecast_horizon = 10\n","# Prepare Input-Output Sequences\n","def create_sequences(data, time_steps, forecast_horizon):\n","    X_past, X_future, y = [], [], []\n","    for i in range(len(data) - time_steps - forecast_horizon):\n","        X_past.append(data[i:i+time_steps])\n","        X_future.append(data[i+time_steps:i+time_steps+forecast_horizon])\n","        y.append(data[i+time_steps:i+time_steps+forecast_horizon])\n","    return np.array(X_past), np.array(X_future), np.array(y)\n","\n","X_past, X_future, y = create_sequences(data_scaled, time_steps, forecast_horizon)\n","#X_static = np.zeros((X_past.shape[0], 1))"]},{"cell_type":"code","execution_count":null,"id":"c1e42e09-2798-43de-80f1-998da51d500d","metadata":{"id":"c1e42e09-2798-43de-80f1-998da51d500d","outputId":"8d122b1d-dcaa-40e3-fde8-a0708f98aced"},"outputs":[{"data":{"text/plain":["(26341, 30, 48)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["X_past.shape"]},{"cell_type":"code","execution_count":null,"id":"d3273f93-3c76-41c3-b535-936a24ee5fab","metadata":{"id":"d3273f93-3c76-41c3-b535-936a24ee5fab","outputId":"5881e517-cd04-4ad9-ada3-0920b6539ba3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_1 (InputLayer)        [(None, 30, 48)]             0         []                            \n","                                                                                                  \n"," past_VSN_weights (Dense)    (None, 30, 48)               2352      ['input_1[0][0]']             \n","                                                                                                  \n"," multiply (Multiply)         (None, 30, 48)               0         ['input_1[0][0]',             \n","                                                                     'past_VSN_weights[0][0]']    \n","                                                                                                  \n"," past_LSTM (LSTM)            (None, 30, 64)               28928     ['multiply[0][0]']            \n","                                                                                                  \n"," input_2 (InputLayer)        [(None, 10, 48)]             0         []                            \n","                                                                                                  \n"," multi_head_attention (Mult  (None, 30, 64)               265280    ['past_LSTM[0][0]',           \n"," iHeadAttention)                                                     'past_LSTM[0][0]']           \n","                                                                                                  \n"," future_VSN_weights (Dense)  (None, 10, 48)               2352      ['input_2[0][0]']             \n","                                                                                                  \n"," dropout (Dropout)           (None, 30, 64)               0         ['multi_head_attention[0][0]']\n","                                                                                                  \n"," multiply_1 (Multiply)       (None, 10, 48)               0         ['input_2[0][0]',             \n","                                                                     'future_VSN_weights[0][0]']  \n","                                                                                                  \n"," tf.__operators__.add (TFOp  (None, 30, 64)               0         ['past_LSTM[0][0]',           \n"," Lambda)                                                             'dropout[0][0]']             \n","                                                                                                  \n"," future_LSTM (LSTM)          (None, 10, 64)               28928     ['multiply_1[0][0]']          \n","                                                                                                  \n"," layer_normalization (Layer  (None, 30, 64)               128       ['tf.__operators__.add[0][0]']\n"," Normalization)                                                                                   \n","                                                                                                  \n"," multi_head_attention_1 (Mu  (None, 10, 64)               265280    ['future_LSTM[0][0]',         \n"," ltiHeadAttention)                                                   'layer_normalization[0][0]'] \n","                                                                                                  \n"," dropout_1 (Dropout)         (None, 10, 64)               0         ['multi_head_attention_1[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," tf.__operators__.add_1 (TF  (None, 10, 64)               0         ['future_LSTM[0][0]',         \n"," OpLambda)                                                           'dropout_1[0][0]']           \n","                                                                                                  \n"," layer_normalization_1 (Lay  (None, 10, 64)               128       ['tf.__operators__.add_1[0][0]\n"," erNormalization)                                                   ']                            \n","                                                                                                  \n"," dense (Dense)               (None, 10, 128)              8320      ['layer_normalization_1[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," dense_1 (Dense)             (None, 10, 128)              16512     ['dense[0][0]']               \n","                                                                                                  \n"," multiply_2 (Multiply)       (None, 10, 128)              0         ['dense_1[0][0]',             \n","                                                                     'dense[0][0]']               \n","                                                                                                  \n"," dense_2 (Dense)             (None, 10, 256)              33024     ['multiply_2[0][0]']          \n","                                                                                                  \n"," dense_3 (Dense)             (None, 10, 128)              32896     ['dense_2[0][0]']             \n","                                                                                                  \n"," dropout_2 (Dropout)         (None, 10, 128)              0         ['dense_3[0][0]']             \n","                                                                                                  \n"," tf.__operators__.add_2 (TF  (None, 10, 128)              0         ['multiply_2[0][0]',          \n"," OpLambda)                                                           'dropout_2[0][0]']           \n","                                                                                                  \n"," layer_normalization_2 (Lay  (None, 10, 128)              256       ['tf.__operators__.add_2[0][0]\n"," erNormalization)                                                   ']                            \n","                                                                                                  \n"," tf.__operators__.getitem (  (None, 128)                  0         ['layer_normalization_2[0][0]'\n"," SlicingOpLambda)                                                   ]                             \n","                                                                                                  \n"," dense_4 (Dense)             (None, 480)                  61920     ['tf.__operators__.getitem[0][\n","                                                                    0]']                          \n","                                                                                                  \n"," tf.reshape (TFOpLambda)     (None, 10, 48)               0         ['dense_4[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 746304 (2.85 MB)\n","Trainable params: 746304 (2.85 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout, LSTM, Multiply\n","from tensorflow.keras.models import Model\n","\n","# Model Parameters\n","time_steps = 30   # Past 30 days as input\n","num_features = X_past.shape[2]  # Max Temp, Min Temp, Rainfall, Snowfall\n","forecast_horizon = 10  # Predict next 10 days\n","d_model = 128    # Embedding size\n","num_heads = 8    # Multi-head attention\n","ff_dim = 256     # Feedforward layer size\n","dropout_rate = 0.1\n","lstm_units = 64  # LSTM hidden state size\n","\n","# Variable Selection Network (VSM)\n","def variable_selection_network(inputs, name=\"VSN\"):\n","    selection_weights = Dense(num_features, activation='softmax', name=f\"{name}_weights\")(inputs)\n","    return Multiply()([inputs, selection_weights])  # Element-wise multiplication\n","\n","# Input Layers\n","past_inputs = Input(shape=(time_steps, num_features))  # Past observed variables\n","future_inputs = Input(shape=(forecast_horizon, num_features))  # Future known variables\n","\n","# Apply Variable Selection Network\n","past_selected = variable_selection_network(past_inputs, name=\"past_VSN\")\n","future_selected = variable_selection_network(future_inputs, name=\"future_VSN\")\n","\n","# LSTM-Based Encoding\n","past_lstm = LSTM(lstm_units, return_sequences=True, name=\"past_LSTM\")(past_selected)\n","future_lstm = LSTM(lstm_units, return_sequences=True, name=\"future_LSTM\")(future_selected)\n","\n","# Multi-Head Attention on Encoded Data\n","encoder_attention = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(past_lstm, past_lstm)\n","encoder_attention = Dropout(dropout_rate)(encoder_attention)\n","encoder_attention = LayerNormalization(epsilon=1e-6)(past_lstm + encoder_attention)\n","\n","# Decoder Attention (Cross-Attention)\n","decoder_attention = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(future_lstm, encoder_attention)\n","decoder_attention = Dropout(dropout_rate)(decoder_attention)\n","decoder_attention = LayerNormalization(epsilon=1e-6)(future_lstm + decoder_attention)\n","\n","# Reshape decoder_attention to match d_model for gating\n","decoder_attention_resized = Dense(d_model)(decoder_attention)  # Align dimensions with d_model\n","\n","# Gating Mechanism\n","gate = Dense(d_model, activation='sigmoid')(decoder_attention_resized)\n","gated_output = Multiply()([gate, decoder_attention_resized])  # Element-wise multiplication\n","\n","# Feedforward Network\n","ff_output = Dense(ff_dim, activation=\"relu\")(gated_output)\n","ff_output = Dense(d_model)(ff_output)\n","ff_output = Dropout(dropout_rate)(ff_output)\n","ff_output = LayerNormalization(epsilon=1e-6)(gated_output + ff_output)\n","\n","# Output Layer (Predict next 10 days)\n","outputs = Dense(forecast_horizon * num_features)(ff_output[:, -1, :])  # Use last time step\n","outputs = tf.reshape(outputs, (-1, forecast_horizon, num_features))  # Reshape output\n","\n","# Define the Model\n","model = Model(inputs=[past_inputs, future_inputs], outputs=outputs)\n","\n","# Compile Model\n","model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n","\n","# Model Summary\n","model.summary()\n","\n"]},{"cell_type":"code","execution_count":null,"id":"ef439bdc-59ec-4e28-b800-c818991a3d10","metadata":{"id":"ef439bdc-59ec-4e28-b800-c818991a3d10"},"outputs":[],"source":["from tensorflow.keras.callbacks import EarlyStopping\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # Monitor validation loss\n","    patience=5,          # Stop training after 3 epochs of no improvement\n","    restore_best_weights=True  # Restore the best model weights\n",")"]},{"cell_type":"code","execution_count":null,"id":"30549b92-a46d-4846-800f-9f89d3ba96b9","metadata":{"id":"30549b92-a46d-4846-800f-9f89d3ba96b9","outputId":"4e6969b0-536f-46a2-d701-81fb0f368042"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","330/330 [==============================] - 85s 213ms/step - loss: 0.0507 - mae: 0.1611 - val_loss: 0.0291 - val_mae: 0.1214\n","Epoch 2/100\n","330/330 [==============================] - 81s 244ms/step - loss: 0.0192 - mae: 0.0995 - val_loss: 0.0136 - val_mae: 0.0799\n","Epoch 3/100\n","188/330 [================>.............] - ETA: 30s - loss: 0.0134 - mae: 0.0810"]}],"source":["model.fit([X_past, X_future], y, epochs=100, batch_size=64, validation_split=0.2, callbacks=[early_stopping])"]},{"cell_type":"code","execution_count":null,"id":"45538408-f5d8-4965-812d-1c789984b01d","metadata":{"id":"45538408-f5d8-4965-812d-1c789984b01d"},"outputs":[],"source":["split = int(len(X_past) * 0.8)  # Assuming an 80/20 train-test split\n","X_train_past, X_past_test = X_past[:split], X_past[split:]\n","X_train_future, X_future_test= X_future[:split], X_future[split:]\n","X_train, X_test = (X_past[:split], X_future[:split]), (X_past[split:], X_future[split:])"]},{"cell_type":"code","execution_count":null,"id":"50cdd39a-cdc7-408a-a6fb-bb225cf300e1","metadata":{"id":"50cdd39a-cdc7-408a-a6fb-bb225cf300e1","outputId":"d002a159-c5a7-44f9-a2f3-ebf8b782c9d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 2s 2s/step\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","\n","# Prepare the encoder input (last 30 days for past data)\n","encoder_input_past = X_past_test[-1:]  # Shape: (1, 30, 5)\n","\n","# Prepare the future known inputs (last 10 days for future data)\n","encoder_input_future = X_future_test[-1:]  # Shape: (1, 10, 5)\n","\n","# If necessary, reshape the inputs to match the model's expected input shape\n","# If the model accepts two inputs (past and future data), you can pass them as a list\n","encoder_input = [encoder_input_past, encoder_input_future]  # Shape: [(1, 30, 5), (1, 10, 5)]\n","\n","# Prepare the future known inputs (use zeros if unknown, depending on the model's expectation)\n","future_input = np.zeros((1, forecast_horizon, encoder_input_past[0].shape[1]))  # Shape: (1, 10, 5)\n","\n","# Predict the next 10 days using TFT model\n","predicted_10_days = model.predict([encoder_input_past, future_input])\n","\n","# If you want to rescale back the predictions, make sure to reshape correctly\n","predicted_10_days_scaled = scaler.inverse_transform(predicted_10_days[0])  # Assuming scaler is fitted on the model's output\n"]},{"cell_type":"code","execution_count":null,"id":"5c647581-13bb-4d57-b84e-654bd859c1fe","metadata":{"id":"5c647581-13bb-4d57-b84e-654bd859c1fe","outputId":"19390414-add2-406c-d24b-ffb96fef7868"},"outputs":[{"data":{"text/plain":["array([[ 6.2047234, -7.9987087],\n","       [ 3.8205767, -3.9174216],\n","       [ 5.454963 , -8.560996 ],\n","       [ 7.780187 , -4.948758 ],\n","       [ 7.7944145, -2.916914 ],\n","       [ 8.084926 , -4.020312 ],\n","       [ 9.82324  , -4.624658 ],\n","       [13.54732  , -2.2530513],\n","       [14.76525  ,  1.3223221],\n","       [10.124108 ,  2.2637098]], dtype=float32)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["np.set_printoptions(suppress=True)\n","value=predicted_10_days_scaled[:,[0,1]]\n","value"]},{"cell_type":"code","execution_count":null,"id":"b5013629-d9e5-4fcd-af83-614b7d0e17da","metadata":{"id":"b5013629-d9e5-4fcd-af83-614b7d0e17da"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}